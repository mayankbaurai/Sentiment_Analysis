{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_transformation_with_gensim___Sentiment_Analysis_lyst7227-with LSTM layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyc_0lfv98xf"
      },
      "source": [
        "# The data\n",
        "\n",
        "   ##  About the data\n",
        "The analysis seeks to establish transformation of word into vectors on any text. We are not concerned about whether the text data has label or not. The data set supplied consists of  **50000 IMDB reviews**  with review ID on a certain movie  with no labels.We'll use this unlabelled data to train a model. which can be applied on test data.\n",
        "\n",
        "Please visit the site to download the data\n",
        "https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qjeipfq-Xvy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUO7x4uTqEyv"
      },
      "source": [
        "## Import the data\n",
        "\n",
        "The data was imported from local repository using the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6nYK0Zs-ePR",
        "outputId": "29a96a96-24f1-4c0b-a49b-527e654823ec",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ffbe7bb-a224-4b5d-bc0f-b00b6aa258d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ffbe7bb-a224-4b5d-bc0f-b00b6aa258d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb2PtvNs-ezJ"
      },
      "source": [
        "\n",
        "df=pd.read_csv(\"unlabeledTrainData.tsv\",delimiter=\"\\t\",quoting=3,header=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beTir5Bc-e13",
        "outputId": "89157c5e-b7cf-45f3-be28-49debb276e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGqHLWu-e7m"
      },
      "source": [
        "import re,string"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEa71UBQe9X7"
      },
      "source": [
        "##  Data Cleaning\n",
        "We've gone through the reviews & detected punctuations in many reviews.The punctuations don't contribute anything to our analysis & moreover they are considered as unique word & distort the meaning of other words.This is why the data needs to be cleaned before we jump into core analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWxkM_PZ-e-h"
      },
      "source": [
        "def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n",
        "  try:\n",
        "    string=re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n",
        "    string=re.sub(r\"[^A-Za-z]\",\" \",string)\n",
        "    words=string.strip().lower().split()\n",
        "    return \" \".join(words)\n",
        "  except:\n",
        "    return \" \"\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRrc9brjJyEP"
      },
      "source": [
        "Above we defined a function called **clean_string** & this function we have applied on the raw review column and created a new column(**clean_review**) to save the cleaned reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rZpIB7i-fBK"
      },
      "source": [
        "df['clean_review']=df.review.apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrIOSWx3-fFk",
        "outputId": "1b3bf988-8736-4704-ae52-b1d72a71a735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print (\"No.of samples \\n:\",(len(df)))\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of samples \n",
            ": 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "      <td>watching time chasers it obvious that it was m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "      <td>i saw this film about years ago and remember i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "      <td>minor spoilers br br in new york joan barnard ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "      <td>i went to see this film with a great deal of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "      <td>yes i agree with everyone on this site this mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                       clean_review\n",
              "0   \"9999_0\"  ...  watching time chasers it obvious that it was m...\n",
              "1  \"45057_0\"  ...  i saw this film about years ago and remember i...\n",
              "2  \"15561_0\"  ...  minor spoilers br br in new york joan barnard ...\n",
              "3   \"7161_0\"  ...  i went to see this film with a great deal of e...\n",
              "4  \"43971_0\"  ...  yes i agree with everyone on this site this mo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEWVMOiItP2L"
      },
      "source": [
        "If we look at the data now, we'll not notice any punctuations in the **clean_review** column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcKWqrLo2ZRz"
      },
      "source": [
        "#  Word2Vec with Gensim(The Word2Vec toolkit)\n",
        "\n",
        "Gensim is an open source Python library for natural language processing, with a focus on topic modeling.Gensim was developed and is maintained by the Czech natural language processing researcher **Radim Řehůřek** and his company RaRe Technologies.\n",
        "\n",
        "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. Most notably for this tutorial, it supports an implementation of the** Word2Vec word embedding** for learning new word vectors from text.\n",
        "\n",
        "It also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, we dig a little \"deeper\" into sentiment analysis. Google's Word2Vec is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning and **semantic relationships** among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4OuxlUSuPy7"
      },
      "source": [
        "**Please install & import the gensim everytime you work on Google colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK0rq-GZ-e45"
      },
      "source": [
        "!pip install gensim --quiet                                      "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16M51r6GOuFC"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgGRlg9MuehZ"
      },
      "source": [
        "**Since we are going to work with words, so we are required to split the each review so that we can have word tokens.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVP0tOb-fJL"
      },
      "source": [
        "Document=[]\n",
        "for doc in df['clean_review']:\n",
        "  Document.append(doc.split(' '))                             "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tta5zrdnrlft",
        "outputId": "364c1a17-1ad7-47a1-8b53-ec62fcf6e508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(Document)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfp2mtdQu8oU"
      },
      "source": [
        "**Let us explore split reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV4hRqzwVt4V",
        "outputId": "2028443e-a5bf-46cc-a3be-c388c1075209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Document[10][6:13]                                                                # This what is there in 10th Document starting from 6 till 12"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie', 'i', 'am', 'not', 'sure', 'whether', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQWDFXrYVt7G",
        "outputId": "832d6c44-ec38-40f8-e363-55921b450635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(len(Document[10]))                                                          # Lenth of the 10th document ,  It has 524 words in it\n",
        "print(Document[10])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "524\n",
            "['after', 'reading', 'the', 'comments', 'for', 'this', 'movie', 'i', 'am', 'not', 'sure', 'whether', 'i', 'should', 'be', 'angry', 'sad', 'or', 'sickened', 'seeing', 'comments', 'typical', 'of', 'people', 'who', 'a', 'know', 'absolutely', 'nothing', 'about', 'the', 'military', 'or', 'b', 'who', 'base', 'everything', 'they', 'think', 'they', 'know', 'on', 'movies', 'like', 'this', 'or', 'on', 'cnn', 'reports', 'about', 'abu', 'gharib', 'makes', 'me', 'wonder', 'about', 'the', 'state', 'of', 'intellectual', 'stimulation', 'in', 'the', 'world', 'br', 'br', 'at', 'the', 'time', 'i', 'type', 'this', 'the', 'number', 'of', 'people', 'in', 'the', 'us', 'military', 'million', 'on', 'active', 'duty', 'with', 'another', 'almost', 'in', 'the', 'guard', 'and', 'reserves', 'for', 'a', 'total', 'of', 'roughly', 'million', 'br', 'br', 'the', 'number', 'of', 'people', 'indicted', 'for', 'abuses', 'at', 'at', 'abu', 'gharib', 'currently', 'less', 'than', 'br', 'br', 'that', 'makes', 'the', 'total', 'of', 'people', 'indicted', 'of', 'the', 'total', 'military', 'even', 'if', 'you', 'indict', 'every', 'single', 'military', 'member', 'that', 'ever', 'stepped', 'in', 'to', 'abu', 'gharib', 'you', 'would', 'not', 'come', 'close', 'to', 'making', 'that', 'a', 'whole', 'number', 'br', 'br', 'the', 'flaws', 'in', 'this', 'movie', 'would', 'take', 'years', 'to', 'cover', 'i', 'understand', 'that', 'it', 's', 'supposed', 'to', 'be', 'sarcastic', 'but', 'in', 'reality', 'the', 'writer', 'and', 'director', 'are', 'trying', 'to', 'make', 'commentary', 'about', 'the', 'state', 'of', 'the', 'military', 'without', 'an', 'enemy', 'to', 'fight', 'in', 'reality', 'the', 'us', 'military', 'has', 'been', 'at', 'its', 'busiest', 'when', 'there', 'are', 'not', 'conflicts', 'going', 'on', 'the', 'military', 'is', 'the', 'first', 'called', 'for', 'disaster', 'relief', 'and', 'humanitarian', 'aid', 'missions', 'when', 'the', 'tsunami', 'hit', 'indonesia', 'devestating', 'the', 'region', 'the', 'us', 'military', 'was', 'the', 'first', 'on', 'the', 'scene', 'when', 'the', 'chaos', 'of', 'the', 'situation', 'overwhelmed', 'the', 'local', 'governments', 'it', 'was', 'military', 'leadership', 'who', 'looked', 'at', 'their', 'people', 'the', 'same', 'people', 'this', 'movie', 'mocks', 'and', 'said', 'make', 'it', 'happen', 'within', 'hours', 'food', 'aid', 'was', 'reaching', 'isolated', 'villages', 'within', 'days', 'airfields', 'were', 'built', 'cargo', 'aircraft', 'started', 'landing', 'and', 'a', 'food', 'distribution', 'system', 'was', 'up', 'and', 'running', 'hours', 'and', 'days', 'not', 'weeks', 'and', 'months', 'yes', 'there', 'are', 'unscrupulous', 'people', 'in', 'the', 'us', 'military', 'but', 'then', 'there', 'are', 'in', 'every', 'walk', 'of', 'life', 'every', 'occupation', 'but', 'to', 'see', 'people', 'on', 'this', 'website', 'decide', 'that', 'million', 'men', 'and', 'women', 'are', 'all', 'criminal', 'with', 'nothing', 'on', 'their', 'minds', 'but', 'thoughts', 'of', 'destruction', 'or', 'mayhem', 'is', 'an', 'absolute', 'disservice', 'to', 'the', 'things', 'that', 'they', 'do', 'every', 'day', 'one', 'person', 'on', 'this', 'website', 'even', 'went', 'so', 'far', 'as', 'to', 'say', 'that', 'military', 'members', 'are', 'in', 'it', 'for', 'personal', 'gain', 'wow', 'entry', 'level', 'personnel', 'make', 'just', 'under', 'an', 'hour', 'assuming', 'a', 'hour', 'work', 'week', 'of', 'course', 'many', 'work', 'much', 'more', 'than', 'hours', 'a', 'week', 'and', 'those', 'in', 'harm', 's', 'way', 'typically', 'put', 'in', 'hour', 'days', 'for', 'months', 'on', 'end', 'that', 'makes', 'the', 'pay', 'well', 'under', 'minimum', 'wage', 'so', 'much', 'for', 'personal', 'gain', 'i', 'beg', 'you', 'please', 'make', 'yourself', 'familiar', 'with', 'the', 'world', 'around', 'you', 'go', 'to', 'a', 'nearby', 'base', 'get', 'a', 'visitor', 'pass', 'and', 'meet', 'some', 'of', 'the', 'men', 'and', 'women', 'you', 'are', 'so', 'quick', 'to', 'disparage', 'you', 'would', 'be', 'surprised', 'the', 'military', 'no', 'longer', 'accepts', 'people', 'in', 'lieu', 'of', 'prison', 'time', 'they', 'require', 'a', 'minimum', 'of', 'a', 'ged', 'and', 'prefer', 'a', 'high', 'school', 'diploma', 'the', 'middle', 'ranks', 'are', 'expected', 'to', 'get', 'a', 'minimum', 'of', 'undergraduate', 'degrees', 'and', 'the', 'upper', 'ranks', 'are', 'encouraged', 'to', 'get', 'advanced', 'degrees']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jamR9vRCPJM-"
      },
      "source": [
        "import logging                                                                    # Please import logging to keep & check information regarding word2vec transformation"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fdKWAs2VuAX",
        "outputId": "af8fd94a-0e04-496b-c49a-a07d01e68780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "model=gensim.models.Word2Vec(Document,                                           # List of reviews\n",
        "                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n",
        "                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n",
        "                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n",
        "                          window=5)                                              # 5 neighbors on the either side of a word"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 10:49:17,455 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2020-10-21 10:49:17,457 : INFO : collecting all words and their counts\n",
            "2020-10-21 10:49:17,459 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-10-21 10:49:17,875 : INFO : PROGRESS: at sentence #10000, processed 2399440 words, keeping 51654 word types\n",
            "2020-10-21 10:49:18,302 : INFO : PROGRESS: at sentence #20000, processed 4835846 words, keeping 69077 word types\n",
            "2020-10-21 10:49:18,726 : INFO : PROGRESS: at sentence #30000, processed 7267977 words, keeping 81515 word types\n",
            "2020-10-21 10:49:19,152 : INFO : PROGRESS: at sentence #40000, processed 9669772 words, keeping 91685 word types\n",
            "2020-10-21 10:49:19,580 : INFO : collected 100479 word types from a corpus of 12084660 raw words and 50000 sentences\n",
            "2020-10-21 10:49:19,580 : INFO : Loading a fresh vocabulary\n",
            "2020-10-21 10:49:19,929 : INFO : effective_min_count=10 retains 28322 unique words (28% of original 100479, drops 72157)\n",
            "2020-10-21 10:49:19,929 : INFO : effective_min_count=10 leaves 11910457 word corpus (98% of original 12084660, drops 174203)\n",
            "2020-10-21 10:49:20,015 : INFO : deleting the raw counts dictionary of 100479 items\n",
            "2020-10-21 10:49:20,019 : INFO : sample=0.001 downsamples 49 most-common words\n",
            "2020-10-21 10:49:20,020 : INFO : downsampling leaves estimated 8817283 word corpus (74.0% of prior 11910457)\n",
            "2020-10-21 10:49:20,104 : INFO : estimated required memory for 28322 words and 50 dimensions: 25489800 bytes\n",
            "2020-10-21 10:49:20,105 : INFO : resetting layer weights\n",
            "2020-10-21 10:49:25,250 : INFO : training model with 4 workers on 28322 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-10-21 10:49:26,285 : INFO : EPOCH 1 - PROGRESS: at 6.35% examples, 542818 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:27,295 : INFO : EPOCH 1 - PROGRESS: at 12.95% examples, 552938 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:28,324 : INFO : EPOCH 1 - PROGRESS: at 19.51% examples, 556147 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-21 10:49:29,342 : INFO : EPOCH 1 - PROGRESS: at 26.09% examples, 559684 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-21 10:49:30,343 : INFO : EPOCH 1 - PROGRESS: at 32.48% examples, 560691 words/s, in_qsize 8, out_qsize 0\n",
            "2020-10-21 10:49:31,350 : INFO : EPOCH 1 - PROGRESS: at 38.56% examples, 557255 words/s, in_qsize 8, out_qsize 0\n",
            "2020-10-21 10:49:32,367 : INFO : EPOCH 1 - PROGRESS: at 44.92% examples, 557084 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-21 10:49:33,375 : INFO : EPOCH 1 - PROGRESS: at 51.39% examples, 558540 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:34,375 : INFO : EPOCH 1 - PROGRESS: at 57.82% examples, 559632 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:35,375 : INFO : EPOCH 1 - PROGRESS: at 64.04% examples, 559653 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:36,387 : INFO : EPOCH 1 - PROGRESS: at 70.47% examples, 559051 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:37,403 : INFO : EPOCH 1 - PROGRESS: at 76.95% examples, 559444 words/s, in_qsize 8, out_qsize 0\n",
            "2020-10-21 10:49:38,405 : INFO : EPOCH 1 - PROGRESS: at 83.62% examples, 560926 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:39,411 : INFO : EPOCH 1 - PROGRESS: at 90.17% examples, 561607 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:40,419 : INFO : EPOCH 1 - PROGRESS: at 96.65% examples, 562429 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:40,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-10-21 10:49:40,905 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-21 10:49:40,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-21 10:49:40,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-21 10:49:40,915 : INFO : EPOCH - 1 : training on 12084660 raw words (8817091 effective words) took 15.7s, 563042 effective words/s\n",
            "2020-10-21 10:49:41,934 : INFO : EPOCH 2 - PROGRESS: at 6.26% examples, 544741 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:42,942 : INFO : EPOCH 2 - PROGRESS: at 12.86% examples, 554714 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:43,943 : INFO : EPOCH 2 - PROGRESS: at 19.53% examples, 565178 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:44,972 : INFO : EPOCH 2 - PROGRESS: at 25.80% examples, 559578 words/s, in_qsize 5, out_qsize 2\n",
            "2020-10-21 10:49:45,975 : INFO : EPOCH 2 - PROGRESS: at 32.47% examples, 564711 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:46,998 : INFO : EPOCH 2 - PROGRESS: at 38.88% examples, 564008 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:48,001 : INFO : EPOCH 2 - PROGRESS: at 45.29% examples, 564982 words/s, in_qsize 8, out_qsize 0\n",
            "2020-10-21 10:49:49,010 : INFO : EPOCH 2 - PROGRESS: at 51.62% examples, 563656 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:50,050 : INFO : EPOCH 2 - PROGRESS: at 58.28% examples, 564141 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:51,051 : INFO : EPOCH 2 - PROGRESS: at 64.60% examples, 564296 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:52,053 : INFO : EPOCH 2 - PROGRESS: at 71.08% examples, 564418 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:53,056 : INFO : EPOCH 2 - PROGRESS: at 77.34% examples, 563219 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:54,083 : INFO : EPOCH 2 - PROGRESS: at 83.84% examples, 562255 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:55,102 : INFO : EPOCH 2 - PROGRESS: at 90.44% examples, 562323 words/s, in_qsize 8, out_qsize 2\n",
            "2020-10-21 10:49:56,123 : INFO : EPOCH 2 - PROGRESS: at 96.96% examples, 563076 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:56,543 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-10-21 10:49:56,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-21 10:49:56,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-21 10:49:56,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-21 10:49:56,568 : INFO : EPOCH - 2 : training on 12084660 raw words (8820100 effective words) took 15.6s, 563694 effective words/s\n",
            "2020-10-21 10:49:57,583 : INFO : EPOCH 3 - PROGRESS: at 6.34% examples, 554269 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:58,583 : INFO : EPOCH 3 - PROGRESS: at 12.86% examples, 557725 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:49:59,590 : INFO : EPOCH 3 - PROGRESS: at 19.35% examples, 561114 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:00,608 : INFO : EPOCH 3 - PROGRESS: at 25.80% examples, 561567 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:01,616 : INFO : EPOCH 3 - PROGRESS: at 32.31% examples, 562874 words/s, in_qsize 8, out_qsize 1\n",
            "2020-10-21 10:50:02,651 : INFO : EPOCH 3 - PROGRESS: at 38.71% examples, 561269 words/s, in_qsize 7, out_qsize 1\n",
            "2020-10-21 10:50:03,661 : INFO : EPOCH 3 - PROGRESS: at 45.06% examples, 560942 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:04,681 : INFO : EPOCH 3 - PROGRESS: at 51.62% examples, 562037 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:05,682 : INFO : EPOCH 3 - PROGRESS: at 57.97% examples, 561976 words/s, in_qsize 8, out_qsize 1\n",
            "2020-10-21 10:50:06,689 : INFO : EPOCH 3 - PROGRESS: at 64.44% examples, 563463 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:07,696 : INFO : EPOCH 3 - PROGRESS: at 71.36% examples, 566618 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:08,715 : INFO : EPOCH 3 - PROGRESS: at 78.26% examples, 569210 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:09,731 : INFO : EPOCH 3 - PROGRESS: at 85.07% examples, 570463 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:10,741 : INFO : EPOCH 3 - PROGRESS: at 91.70% examples, 570751 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:11,749 : INFO : EPOCH 3 - PROGRESS: at 98.16% examples, 570492 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:11,990 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-10-21 10:50:11,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-21 10:50:12,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-21 10:50:12,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-21 10:50:12,007 : INFO : EPOCH - 3 : training on 12084660 raw words (8817004 effective words) took 15.4s, 571322 effective words/s\n",
            "2020-10-21 10:50:13,049 : INFO : EPOCH 4 - PROGRESS: at 6.43% examples, 548846 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:14,061 : INFO : EPOCH 4 - PROGRESS: at 13.01% examples, 555172 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:15,076 : INFO : EPOCH 4 - PROGRESS: at 19.53% examples, 558563 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:16,080 : INFO : EPOCH 4 - PROGRESS: at 26.00% examples, 561059 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:17,083 : INFO : EPOCH 4 - PROGRESS: at 32.40% examples, 561610 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:18,083 : INFO : EPOCH 4 - PROGRESS: at 38.73% examples, 562298 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:19,086 : INFO : EPOCH 4 - PROGRESS: at 45.06% examples, 562372 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:20,088 : INFO : EPOCH 4 - PROGRESS: at 51.23% examples, 560080 words/s, in_qsize 8, out_qsize 0\n",
            "2020-10-21 10:50:21,088 : INFO : EPOCH 4 - PROGRESS: at 57.38% examples, 558682 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:22,092 : INFO : EPOCH 4 - PROGRESS: at 63.64% examples, 558590 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:23,108 : INFO : EPOCH 4 - PROGRESS: at 70.14% examples, 558518 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:24,120 : INFO : EPOCH 4 - PROGRESS: at 76.48% examples, 557988 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-21 10:50:25,146 : INFO : EPOCH 4 - PROGRESS: at 83.02% examples, 557948 words/s, in_qsize 8, out_qsize 1\n",
            "2020-10-21 10:50:26,148 : INFO : EPOCH 4 - PROGRESS: at 89.48% examples, 557941 words/s, in_qsize 8, out_qsize 2\n",
            "2020-10-21 10:50:27,153 : INFO : EPOCH 4 - PROGRESS: at 95.79% examples, 558160 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:27,786 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-10-21 10:50:27,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-21 10:50:27,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-21 10:50:27,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-21 10:50:27,808 : INFO : EPOCH - 4 : training on 12084660 raw words (8816012 effective words) took 15.8s, 558321 effective words/s\n",
            "2020-10-21 10:50:28,819 : INFO : EPOCH 5 - PROGRESS: at 6.26% examples, 549034 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:29,864 : INFO : EPOCH 5 - PROGRESS: at 12.85% examples, 546664 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:30,879 : INFO : EPOCH 5 - PROGRESS: at 19.35% examples, 552232 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:31,902 : INFO : EPOCH 5 - PROGRESS: at 25.80% examples, 554203 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:32,905 : INFO : EPOCH 5 - PROGRESS: at 32.40% examples, 558902 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:33,934 : INFO : EPOCH 5 - PROGRESS: at 38.81% examples, 558654 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:34,936 : INFO : EPOCH 5 - PROGRESS: at 45.06% examples, 558365 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:35,950 : INFO : EPOCH 5 - PROGRESS: at 51.39% examples, 557534 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:36,952 : INFO : EPOCH 5 - PROGRESS: at 57.82% examples, 558706 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:37,973 : INFO : EPOCH 5 - PROGRESS: at 64.21% examples, 558989 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:38,981 : INFO : EPOCH 5 - PROGRESS: at 70.79% examples, 559844 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-21 10:50:40,001 : INFO : EPOCH 5 - PROGRESS: at 77.25% examples, 560058 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:41,019 : INFO : EPOCH 5 - PROGRESS: at 83.93% examples, 560763 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:42,031 : INFO : EPOCH 5 - PROGRESS: at 90.44% examples, 560770 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:43,068 : INFO : EPOCH 5 - PROGRESS: at 96.96% examples, 561025 words/s, in_qsize 7, out_qsize 0\n",
            "2020-10-21 10:50:43,485 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-10-21 10:50:43,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-21 10:50:43,498 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-21 10:50:43,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-21 10:50:43,513 : INFO : EPOCH - 5 : training on 12084660 raw words (8817593 effective words) took 15.7s, 561701 effective words/s\n",
            "2020-10-21 10:50:43,513 : INFO : training on a 60423300 raw words (44087800 effective words) took 78.3s, 563328 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlVJEoXC5PD"
      },
      "source": [
        "**Please note that after applying Word2Vec function on the clean_review giving all the arguments corretly we have got 28322 words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RYnV85LCq3r",
        "outputId": "3c239f1d-d455-418b-8bc0-d103c23174e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(model.wv.vocab))                                                        # Now the vocab contains 28322 uinque words"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdk_HDQWD0ct"
      },
      "source": [
        "**Let's check the dimension of a vector i.e. the number of words that represent a word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DGahs80Dv6J",
        "outputId": "1cb1a454-45c6-4183-dfc5-df27a8ebce92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.wv.vector_size)                                                       # It means each vector has 50 numbers in it or in other words each word is vector of 5o numbers that we predefined"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmrT73MQsgm",
        "outputId": "43be2e88-e515-4560-c3c0-c88b813ca6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.wv.vectors.shape                                                            # Dimension of the the entire corpus        "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28322, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhGHd2OREPSz"
      },
      "source": [
        "### Let's explore some interesting results of word2vec experiment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db44U_SoVuC6",
        "outputId": "99c7c370-6e7d-4db8-da5c-a68e6aa69b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.wv.most_similar(\"beautiful\")                                                # 10 similar words beautiful,the maximum similarity is 1,minimum is 0.When they are completely similar the \n",
        "                                                                                  # Value will be 1 , when completely dissimilar,the value will be 0."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 10:50:43,544 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8427574634552002),\n",
              " ('stunning', 0.8258716464042664),\n",
              " ('lovely', 0.8205456733703613),\n",
              " ('haunting', 0.7674765586853027),\n",
              " ('wonderful', 0.7243493795394897),\n",
              " ('breathtaking', 0.6949779987335205),\n",
              " ('delightful', 0.6894989013671875),\n",
              " ('captivating', 0.6819925308227539),\n",
              " ('exquisite', 0.6788485646247864),\n",
              " ('touching', 0.6749249696731567)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NbHKeQg6kP9",
        "outputId": "31b6166e-3e15-4b4e-d71c-10ad7d95d975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.wv.most_similar(\"princess\")                                                  # 10 similar words returned with numbers"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.8333976864814758),\n",
              " ('widow', 0.8320186138153076),\n",
              " ('virgin', 0.825754702091217),\n",
              " ('mermaid', 0.7977147102355957),\n",
              " ('maid', 0.788581907749176),\n",
              " ('mistress', 0.777919590473175),\n",
              " ('belle', 0.7779062390327454),\n",
              " ('nurse', 0.777294397354126),\n",
              " ('gal', 0.7713136672973633),\n",
              " ('pianist', 0.7654023766517639)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tDNwJD-fQs",
        "outputId": "6e76c2b3-ca01-4af8-bd64-2c7a299ff1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "model.wv.doesnt_match(\"she talked to me in the evening publicly\".split())         # publicly does not match in the sentence given"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'publicly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3lClNUZFpQE"
      },
      "source": [
        "Below the word **right** is represented by a dense 50 dimensional vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sj-zNbJ6kKo",
        "outputId": "73f0639d-0c30-46dd-d44e-d43c70960f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.wv[\"right\"]                                                                  # right word is represented by 50 numbers in other words the word \"right\" is vector of 50 numbers\n",
        "                                                                                   # 50 numbers are summarized weights because these numbers are obtained in the hidden layer of predefined 50 neurons"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.2482612 , -0.7615603 , -0.66926825,  0.4198517 , -2.5969024 ,\n",
              "        0.12789491, -0.8670942 ,  0.69533634,  1.6492753 , -0.49404773,\n",
              "       -1.3963357 , -1.6735808 , -0.1520036 , -0.75682366,  0.9809886 ,\n",
              "        1.3868773 ,  0.67476207, -1.3309644 ,  1.2740436 , -3.2074842 ,\n",
              "        1.5002445 , -0.71239233,  1.3990104 , -2.0470276 ,  0.7313841 ,\n",
              "       -2.6091316 , -1.0620319 ,  1.0843799 , -0.8973356 , -0.6021738 ,\n",
              "        0.31016988, -2.5905871 ,  0.93534076,  3.2979257 , -1.4854258 ,\n",
              "        2.857121  ,  0.13846502,  0.2556696 ,  1.1610116 , -0.8999849 ,\n",
              "       -1.5554267 , -1.0766469 ,  1.9741303 , -0.26045805,  0.23356478,\n",
              "       -0.9307806 , -2.7861528 ,  0.54626656, -0.02631485,  0.89225674],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnENAcilu0pP",
        "outputId": "96529568-a98a-4952-8aad-39691b0bd751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.wv['great']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.6426506 ,  0.05484062, -1.2672698 ,  0.0847162 ,  5.371844  ,\n",
              "        2.1987514 ,  1.7663705 ,  0.5578455 ,  1.0657201 ,  5.6036015 ,\n",
              "       -0.23015527, -2.7573566 ,  0.13810502, -0.2886024 , -2.2121024 ,\n",
              "        0.6800541 ,  1.4409364 ,  1.2620891 , -0.64830357,  1.0953355 ,\n",
              "        1.7287182 ,  2.8370798 ,  2.4627166 ,  0.42812717,  0.3164176 ,\n",
              "        2.7381628 , -1.4414704 ,  1.9006734 ,  0.13591126,  1.1135874 ,\n",
              "       -0.5841767 , -2.1699212 , -0.74955994,  1.3712415 , -1.2692451 ,\n",
              "        2.9015708 , -0.46379066,  1.2144006 , -1.7756954 , -2.5923414 ,\n",
              "       -0.12859172, -1.050146  , -2.5589857 , -0.4764793 ,  0.5757201 ,\n",
              "        2.653173  , -1.0175519 ,  1.3231046 , -0.6623386 , -2.3848255 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CItdPnnHGk66"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MMsUOIp-fNX",
        "outputId": "e0c0d2a2-4a7f-4b1f-b6de-1b0fbabd83b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model.save(\"word2vec movie-50\")                                                    # We save this model for further use.\n",
        "                                                                                   # Google has such many pre-trained models"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 10:50:43,618 : INFO : saving Word2Vec object under word2vec movie-50, separately None\n",
            "2020-10-21 10:50:43,620 : INFO : not storing attribute vectors_norm\n",
            "2020-10-21 10:50:43,625 : INFO : not storing attribute cum_table\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-10-21 10:50:43,835 : INFO : saved word2vec movie-50\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a1G2kw_6kf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GUgohwEuWlY"
      },
      "source": [
        "# Sentiment Analysis with pre-trained Word2Vec model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQXgw03nEXb"
      },
      "source": [
        "## Overview\n",
        "In this tutorial we'll do Sentiment analysis based on the concept of Word2Vec using our **pre-trained model** with unlabelled data where we've applied **Word2Vec** technique i.e representing a word with a dense vector of **50 numbers**. The unlabelled data has **50000 IMDB movie reviews** & we extracted  some **28000+** unique words after doing some data preprocessing & applying Word2Vec technique with length of 50 numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9hFkqqmnKqC"
      },
      "source": [
        "###Set the seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb44GXhnSkt"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91e2PZR_nX-l"
      },
      "source": [
        "###Load data\n",
        "Data can be downloaded from Kaggle -> https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov9QKZFTnTUu",
        "outputId": "9980ca75-c3b3-4a4f-cb76-35226b0c155f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c64d72a-275d-42a4-b5f7-7181ada93ace\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8c64d72a-275d-42a4-b5f7-7181ada93ace\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving labeledTrainData.tsv to labeledTrainData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T21NoUqcnald",
        "outputId": "618fd2f1-6ce6-48bc-96da-0a5d070f3a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('labeledTrainData.tsv',  #filepath\n",
        "                 header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "print(df1.shape)  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7Bh8CXnq8d"
      },
      "source": [
        "## About the data\n",
        "\n",
        "The labelled data set contains 25000 reviews with label(**Sentiment**). The output column  Sentiment consists of 2 categories[0 & 1]. \n",
        "\n",
        "**0 -- Indicates negative sentiment **               ,  if the rating < 5\n",
        "\n",
        "**1-- Indicates positive sentiment **                  , if the rating >= 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "537_Pz8Rnaoy",
        "outputId": "e47474db-8d21-45cf-d02c-2f9b942709a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df1.iloc[10:15,:]                                                                  # Have 10th & 11th review of the dataset alongwith review id, sentiment."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"11744_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\"7369_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I had a feeling that after \\\"Submerged\\\", thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\"12081_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"note to George Litman, and others: the Myster...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli...\n",
              "12  \"11744_9\"          1  \"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...\n",
              "13   \"7369_1\"          0  \"I had a feeling that after \\\"Submerged\\\", thi...\n",
              "14  \"12081_1\"          0  \"note to George Litman, and others: the Myster..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA0WOP_Mn0s0"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyBpzQpIn6i9"
      },
      "source": [
        "**1.Split Data into Training and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UipXytQsnary"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df1['review'],\n",
        "    df1['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GaoXClWoCYz"
      },
      "source": [
        "**2.Build Tokenizer to get Number sequences for Each review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cQEWFenaut"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vocab size\n",
        "top_words = 10000\n",
        "\n",
        "t = Tokenizer(num_words=top_words)\n",
        "t.fit_on_texts(X_train.tolist())\n",
        "\n",
        "#Get the word index for each of the word in the review\n",
        "X_train = t.texts_to_sequences(X_train.tolist())\n",
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOEpL98doNTN"
      },
      "source": [
        "**3.Pad sequences to make each review size equal Get the word index for each of the word in the review**\n",
        "\n",
        "We  want to bring all the reviewa into same length because we want to build matrix with this dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqXkimj3oXTT"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "\n",
        "#Each review size\n",
        "max_review_length = 300\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post') "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoZCpIZeoc34"
      },
      "source": [
        "## Build Embedding Matrix from Pre-Trained Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5xftICooe2Z",
        "outputId": "fd73443b-1f88-4ce8-c52a-ee3b785b34cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#Install gensim\n",
        "!pip install gensim --quiet\n",
        "\n",
        "#Load pre-trained model\n",
        "import gensim\n",
        "word2vec = gensim.models.Word2Vec.load('word2vec movie-50')\n",
        "\n",
        "#Embedding Length\n",
        "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
        "\n",
        "print('Loaded word2vec model..')\n",
        "print('Model shape: ', word2vec.wv.vectors.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 10:51:04,407 : INFO : loading Word2Vec object from word2vec movie-50\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-10-21 10:51:04,557 : INFO : loading wv recursively from word2vec movie-50.wv.* with mmap=None\n",
            "2020-10-21 10:51:04,558 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-10-21 10:51:04,560 : INFO : loading vocabulary recursively from word2vec movie-50.vocabulary.* with mmap=None\n",
            "2020-10-21 10:51:04,561 : INFO : loading trainables recursively from word2vec movie-50.trainables.* with mmap=None\n",
            "2020-10-21 10:51:04,564 : INFO : setting ignored attribute cum_table to None\n",
            "2020-10-21 10:51:04,566 : INFO : loaded word2vec movie-50\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded word2vec model..\n",
            "Model shape:  (28322, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvXA1a5Zop5M",
        "outputId": "e7baff23-2d10-4f28-a422-0b63ee7668e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2vec.wv.vector_size"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxuznkdnowdn"
      },
      "source": [
        "**Build matrix for current data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5zL8xsAop-d"
      },
      "source": [
        "#Initialize embedding matrix to all zeros\n",
        "embedding_matrix = np.zeros((top_words + 1, # Vocablury size + 1,, we add 1 to vocab size for padding\n",
        "                             embedding_vector_length))\n",
        "\n",
        "#Steps for populating embedding matrix\n",
        "\n",
        "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
        "# word2vec model.\n",
        "#2. If found, update embedding matrix with embeddings for the word \n",
        "# from word2vec model\n",
        "\n",
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > top_words:\n",
        "        break\n",
        "    if word in word2vec.wv.vocab:\n",
        "        embedding_vector = word2vec.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZzFuBkzoqBA",
        "outputId": "4eae54d5-e0db-4db3-f146-70873abcddc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Check embeddings for word 'great'\n",
        "embedding_matrix[t.word_index['great']]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.86859763, -2.9481523 ,  2.64820337,  2.69002867, -1.35399759,\n",
              "       -1.3424865 , -0.86652607,  1.53507364,  1.23525298, -0.48564109,\n",
              "       -3.43691373, -3.68102694,  2.01954794, -1.82383764,  0.52092159,\n",
              "        1.88767529, -1.50249743, -0.69696069,  1.25052619, -1.38550436,\n",
              "        0.71401405,  0.19011979, -1.97235644, -0.67453712, -1.35180855,\n",
              "       -2.44011426, -1.3690747 ,  0.32070279, -0.46759763,  0.29203999,\n",
              "        0.94842374, -1.27779496,  1.90465307,  0.79849088,  0.07805979,\n",
              "       -0.63224143, -0.57747275,  3.71129608, -1.32843566, -0.38882852,\n",
              "        0.36235195,  1.09783888,  3.94461894, -2.0838635 ,  4.42357111,\n",
              "       -1.84352863, -0.73192579, -0.2917054 ,  3.16249442, -0.53603405])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vtp6ZR_1d9D",
        "outputId": "b8b9987d-5b78-4e7a-ee0f-811843b032d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.iloc[0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgKk9JprPvc"
      },
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6oNRfbcoqDi"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten,Input,LSTM\n",
        "\n",
        "#Build a sequential model\n",
        "model1 = Sequential()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpXa42e0rYoc"
      },
      "source": [
        "**Add Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9FUNpgeoqGe"
      },
      "source": [
        "model1.add(Embedding(top_words + 1,\n",
        "                    embedding_vector_length,\n",
        "                    input_length=max_review_length,\n",
        "                    weights=[embedding_matrix],                                    # Pre-trained embedding\n",
        "                    trainable=False)                                               # We do not want to change embedding\n",
        "         )"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFsjGhSXrw7b"
      },
      "source": [
        "Output from Embedding is 3 dimension \n",
        "- batch_size x max_review_length x embedding_vector_length. \n",
        "\n",
        "We need to flatten the output for Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esaAPDRioqLE"
      },
      "source": [
        "#Flatten embedding layer output and flatten layers\n",
        "model1.add(Flatten())                                                             # Flatten enables us to bring down the dimension of the prepared data\n",
        "model1.add(Dense(200,activation='relu'))                                          # Dense layer is for fully connected layer\n",
        "model1.add(Dense(100,activation='relu'))\n",
        "model1.add(Dropout(0.5))                                                          # Dropout is required to avoid overfiting & make the model generalize\n",
        "model1.add(Dense(60,activation='relu'))\n",
        "model1.add(Dropout(0.4))\n",
        "model1.add(Dense(30,activation='relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(1,activation='sigmoid'))                                         # We've used sigmoid because output variable is binary\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xH1o_Swr98W"
      },
      "source": [
        "## Execute the graph\n",
        "\n",
        "Here we'll  use split data to find train & validation accuracy with 10 iterations on 20000 train data & 5000 validation data with batch size of 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n56qw2p1oqJo",
        "outputId": "b2950954-218e-4f61-c3d6-88732d5852f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model1.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=200,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.7162 - accuracy: 0.5405 - val_loss: 0.6259 - val_accuracy: 0.6640\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5783 - accuracy: 0.6995 - val_loss: 0.5301 - val_accuracy: 0.7382\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.7985 - val_loss: 0.5157 - val_accuracy: 0.7514\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3488 - accuracy: 0.8573 - val_loss: 0.5495 - val_accuracy: 0.7462\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2547 - accuracy: 0.8996 - val_loss: 0.6198 - val_accuracy: 0.7466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31bd953828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnFqC8IosK_m",
        "outputId": "d59efee4-294e-4838-bb80-52112e08b492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model1.predict(X_test[10:12])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55645454],\n",
              "       [0.008973  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_yd1JcxUvh",
        "outputId": "7f80d5be-b70e-431d-a76c-29eca607e77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df1.iloc[10:12,:]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAVyObUcLqV9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}